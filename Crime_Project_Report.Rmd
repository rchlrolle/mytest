---
title: "Crime Data in DC Report"
author: "Ellie Ralph, Stephen Deferarri, and Rachel Rolle"
output: pdf_document
---

## Abstract

```         
With discussions of police reform on the rise in addition to the correct police responses and interventions on crime, the conversation around what crimes are actually happening is crucial. We chose to look at Washington, D.C. as the basis of our research to determine the distribution of violent versus nonviolent crime. By analyzing at factors like frequency, time, and geographic location, we were able to disseminate crime hotspots within D.C. This was through creation of code using R as well as ******** We also considered locations of FEMS as a means to discuss EMS response times for violent crimes. 
```

## Introduction

Numerous studies have been conducted on crime in DC regarding youth crime, metro station crime, and the effect of mediation programs (Gottfredson & Soulé, 2005, Irvin-Erickson & La Vigne, 2015, Orme-Johnson et al., 2022). Yet none of these studies have specifically looked at the relationship between crime clusters and violent versus nonviolent crime. Conceptual frameworks have suggested that individuals who have a higher propensity for committing crime are more likely to be associated with violent crimes, but no significant statistical difference has been captured that represents these individuals within a risk factors framework (Ousey et al., 2015).

The two largest national criminal datasets, the Uniform Crime Report (UCR) and the National Crime Victimization Survey (NCVS) have both been described by past researchers as less reliable forms of data due to their lack of reporting consistency across agencies (Eckberg, 2015). National victimization data also suggests that violent crime incidents are only reported less than 50% of the time (Hibdon et al., 2021). Our dataset is one published by the City of Washington, D.C., and is directly from the records of MPD. Though we are unable to corroborate these numbers with criminological survey data, we can use these as a general indication of crime rates within the city.

Part of our research focuses on the relationship between crime hotspots and FEMS data to determine if there is any correlation between the two datasets. Previous findings on FEMS data have found that EMS data may be able to show additional information on violence issues that do not involve police interaction (Hibdon et al., 2021). The utilization of trauma center data has further been cross listed with geospatial violent crime trends, but there has yet to be any statistical significance (Colosimo et al., 2021).

Through the creation of tables, graphs, and maps, we will look at how the overlays of crime factors contribute to one another and whether or not any statistical correlations exist within the culmination of crime characteristics within DC.

## Data & Methods

The DC crime dataset obtained from Open Data DC had data from 2008 through 2023 and contained the following variables:

| Variable Name         | Description                                 | Type         |
|-------------------|-----------------------------------|------------------|
| REPORT_DAT​            | Crime Report Date​                           | Time​         |
| SHIFT​                 | MPD Shift​                                   | Categorical​  |
| METHOD​                | Type of weapon used to commit crime​         | Categorical​  |
| OFFENSE​               | Crime Offense​                               | Categorical​  |
| BLOCK​                 | Block Name​                                  | Categorical​  |
| XBLOCK, YBLOCK​        | Block Coordinates​                           | Geographical​ |
| WARD​                  | Ward​                                        | Categorical​  |
| ANC​                   | Advisory Neighborhood Commission Identifier​ | Categorical​  |
| DISTRICT​              | Police District​                             | Categorical​  |
| PSA​                   | Police Service Areas​                        | Categorical​  |
| NEIGHBORHOOD_CLUSTER​  | Neighborhood Cluster​                        | Categorical​  |
| BLOCK_GROUP​           | Census Block Group​                          | Categorical​  |
| CENSUS_TRACT​          | Census Track​                                | Categorical​  |
| VOTING PRECINCT​       | Voting Precinct​                             | Categorical​  |
| XCOORD, YCOORD​        | X, Y Coordinates of crime incident​          | Geographical​ |
| LATITUDE, LONGITUDE​   | Latitude, Longitude of crime incident​       | Geographical​ |
| BID​                   | Business Improvement District​               | Categorical​  |
| CRIME START, END DATE​ | Start and End dates of crime incident​       | Time​         |

The date variables all coincide with when the crime was reported or when the officer inputting the data judged the crime to have started and ended and are thus subject to human error normally associated with manual data entry coupled with the difficulty of estimating crime start and end times for an officer.

Using this data we were able to engineer the following additional variables:

| Variable Name | Description                 | Type        |
|---------------|-----------------------------|-------------|
| VIOLENT_CRIME​ | Crime Type based on Offense​ | Bool​        |
| YEAR​          | Year​                        | Time​        |
| MONTH​         | Month​                       | Time​        |
| DAY​           | Day of Month​                | Time​        |
| DOW​           | Day of Week​                 | Categorical​ |
| HOUR​          | Hour of Crime​               | Time​        |

The variable VIOLENT_CRIME was derived from MPD's definition of violent crime which encompasses any crime with the following offenses: homicide, sex abuse, assault w/dangerous weapon, and robbery. Property crimes are defined by MPD as the following offenses: burgarly, theft f/auto, theft/other, motor vehicle theft, and arson.

## Exploratory Data Analysis

The variables can be broken down into two different categories: time and location for the crime and we examined them as such. Our primary purpose in our EDA is to see which variables may help to explain any variance in violent crime rates. We start with our time based variables.

![](images/Crime_by_Year.png)

An analysis of violent crime across years reveals decent variation across years with violent crime reaching its lowest point in 2018 and 2019 at 12% with a rebound post COVID.

![](images/full_crime_by_month.png)

When we move our analysis down to the month level we do not see any major changes across months with a tight range of 15%-17% across months for percentage of crime that is classified as violent.

![](images/DOW_w_title.png)

Zooming in further to the week level we are able to again see some significant variation in crime type based on the day of the week with the weekend being particularly more violent than the traditional work week.

![](images/full_crime_by_shift_hour.png)

Finally at the shift and hour level we are able to capture more variation in crime type which we believe will support any models we create in explaining any variability.

Moving onto our location based variables we focus on Ward and Neighborhood block cluster at the exclusion of the other variables including census and polling districts because we are not trying to join on census data for this study and any further location based data risks being redundant and over-complicating our models when they try to account the different categories.

![](images/full_crime_by_ward.png)

![](images/full_crime_by_cluster.png)

Both of our Ward and Neighborhood cluster variables appear to help explain the variability in our crime type.

## Are EMS and Crime Locations Correlated?

We are curious to see if there are any trends between the EMS locations and where the incident took place. Therefore, we plot these points on the map portraying where they were positioned. The key variables we use to create this map are the Ward and EMS locations (this data was provided by the Open Data DC website), and the "VIOLENT_CRIME". The green points are the EMS locations, the blue are the nonviolent crime, and the red is the violent. Once we plot the points, we conclude there was no correlation between the EMS locations and where crime took place. This observation is consistent with the study called "Going beyond the blue: The utility of emergency medical services data in understanding violent crime", which states that they have not found a correlation between EMS locations and where crime takes place (Hibdon et al., 2021).

The white spots on the map look misleading at first glance; it begs the question, why does no crime occur in random spots in the city? The first and largest piece of this is the natural landscape of DC. The Potomac River and the Anacostia River account for large white spaces on the borders of the map; crime cannot be reported in the middle of a river. Additionally, Rock Creek Park is located in the white space of the Northwest corner of the map. The walking trails make it so that most of the crime is reported at the ends of trails where police cars can get to. The Northeast corner is home to the National Arboretum as well as Fort Totten and a golf course, both landscapes that would not be prone to criminal activity unless reported on the outskirts. The US Capital is also under federal jurisdiction in multiple areas, including the National Mall, the White House, and the US Capitol. These areas are outlined within the map in the white space; one can even see the roads that span the National Mall where crimes can be classified under DC's jurisdiction because of the dots that create almost lines around the space. This is all to say that crime is not occurring in these places because of factors unrelated to population and hotspot data, but instead simply because MPD cannot report crime in these areas.

```{r}
#| echo: false

#Get Data from 2008 to 2023
dc.data2023 <- read.csv("https://opendata.arcgis.com/datasets/89561a4f02ba46cca3c42333425d1b87_5.csv", stringsAsFactors = FALSE)
dc.data2022 <- read.csv("https://opendata.arcgis.com/datasets/f9cc541fc8c04106a05a1a4f1e7e813c_4.csv", stringsAsFactors = FALSE)
dc.data2021 <- read.csv("https://opendata.arcgis.com/datasets/619c5bd17ca2411db0689bb0a211783c_3.csv", stringsAsFactors = FALSE)
dc.data2020 <- read.csv("https://opendata.arcgis.com/datasets/f516e0dd7b614b088ad781b0c4002331_2.csv", stringsAsFactors = FALSE)
dc.data2019 <- read.csv("https://opendata.arcgis.com/datasets/f08294e5286141c293e9202fcd3e8b57_1.csv", stringsAsFactors = FALSE)
dc.data2018 <- read.csv("https://opendata.arcgis.com/datasets/38ba41dd74354563bce28a359b59324e_0.csv", stringsAsFactors = FALSE)
dc.data2017 <- read.csv("https://opendata.arcgis.com/datasets/6af5cb8dc38e4bcbac8168b27ee104aa_38.csv", stringsAsFactors = FALSE)
dc.data2016 <- read.csv("https://opendata.arcgis.com/datasets/bda20763840448b58f8383bae800a843_26.csv", stringsAsFactors = FALSE)
dc.data2015 <- read.csv("https://opendata.arcgis.com/datasets/35034fcb3b36499c84c94c069ab1a966_27.csv", stringsAsFactors = FALSE)
dc.data2014 <- read.csv("https://opendata.arcgis.com/datasets/6eaf3e9713de44d3aa103622d51053b5_9.csv", stringsAsFactors = FALSE)
dc.data2013 <- read.csv("https://opendata.arcgis.com/datasets/5fa2e43557f7484d89aac9e1e76158c9_10.csv", stringsAsFactors = FALSE)
dc.data2012 <- read.csv("https://opendata.arcgis.com/datasets/010ac88c55b1409bb67c9270c8fc18b5_11.csv", stringsAsFactors = FALSE)
dc.data2011 <- read.csv("https://opendata.arcgis.com/datasets/9d5485ffae914c5f97047a7dd86e115b_35.csv", stringsAsFactors = FALSE)
dc.data2010 <- read.csv("https://opendata.arcgis.com/datasets/fdacfbdda7654e06a161352247d3a2f0_34.csv", stringsAsFactors = FALSE)
dc.data2009 <- read.csv("https://opendata.arcgis.com/datasets/73cd2f2858714cd1a7e2859f8e6e4de4_33.csv", stringsAsFactors = FALSE)
dc.data2008 <- read.csv("https://opendata.arcgis.com/datasets/180d56a1551c4e76ac2175e63dc0dce9_32.csv", stringsAsFactors = FALSE)


library(tmap)
library(usmap)
library(usmap)
library(plotly)
library(leaflet)
station.locations <- read.csv("https://opendata.arcgis.com/api/v3/datasets/05d048a0aa4845c6a0912f3a9f216992_6/downloads/data?format=csv&spatialRefId=4326&where=1%3D1", stringsAsFactors = FALSE)
library(raster)
library(readr)
library(readxl)
library(sf)
library(maps)
library(spData)
library(tmap)
library(usmap)
library(tidyverse)
library(lubridate)


# library read ins
library(car)
library(lubridate)
library(readr)
library(tidyverse)
library(tseries)


#Date Conversion -----------------------------------------------------
dc.data.temp <- rbind(dc.data2008, dc.data2009, dc.data2010, dc.data2011, dc.data2012, dc.data2013, dc.data2014, dc.data2015, dc.data2016, dc.data2017, dc.data2018, dc.data2019, dc.data2020, dc.data2021, dc.data2022, dc.data2023)

dc.data.temp <- separate(dc.data.temp, REPORT_DAT, into = c("DATE", "TIME"), sep = " ")
dc.data.temp$DATE <- as.Date(dc.data.temp$DATE, format = "%Y/%m/%d")
dc.data.temp$NEIGHBORHOOD_CLUSTER <- toupper(dc.data.temp$NEIGHBORHOOD_CLUSTER)
dc.data.temp$HOUR <- substr(dc.data.temp$TIME, 0, 2)

# DATE: Y, M, D, DOW-------------------------------------------------------------
dc.data.temp$YEAR <- substr(dc.data.temp$DATE, 0, 4)
dc.data.temp$MONTH <- month(dc.data.temp$DATE)
dc.data.temp$DAY <- day(dc.data.temp$DATE)
dc.data.temp$DOW <- weekdays(dc.data.temp$DATE)

# Clean '08-'23 Data -----------------------------------------------
dc.crime.temp <- dc.data.temp%>%
  select(OFFENSE, METHOD, SHIFT, DATE, TIME, YEAR, MONTH, DAY, DOW, START_DATE, LATITUDE, LONGITUDE, BLOCK, WARD, ANC,	DISTRICT, PSA, NEIGHBORHOOD_CLUSTER,	BLOCK_GROUP, CENSUS_TRACT,	VOTING_PRECINCT)

# Need to create our list of violent crimes per DC
viol_crime <- c("HOMICIDE", "SEX ABUSE", "ROBBERY", "ASSAULT W/DANGEROUS WEAPON")

# create our violent_crime column and reorder the columns so its first followed by offense
dc.crime <- dc.crime.temp %>% 
  mutate(VIOLENT_CRIME = ifelse(OFFENSE %in% viol_crime, 1, 0)) %>% 
  select(VIOLENT_CRIME, OFFENSE, everything())

# spit out our CSV
write.csv(dc.crime)

# Exploring Graphs & LM, ANOVA, GLM ------------------------------------------------------------
viol_crime <- c("HOMICIDE", "SEX ABUSE", "ROBBERY", "ASSAULT W/DANGEROUS WEAPON")


# START-REPORT
report_data <- rbind(dc.data2008, dc.data2009, dc.data2010, dc.data2011, dc.data2012, dc.data2013, dc.data2014, dc.data2015, dc.data2016, dc.data2017, dc.data2018, dc.data2019, dc.data2020, dc.data2021, dc.data2022, dc.data2023)%>%
               mutate(
                      VIOLENT_CRIME = ifelse(OFFENSE %in% viol_crime, 1, 0),
                      REPORT = ymd_hms(REPORT_DAT, tz = "America/New_York"),
                      START = ymd_hms(START_DATE, tz = "America/New_York")
               )%>%
               mutate(report_start_diff = as.numeric(difftime(REPORT, START, units = "hours")),
                      ) %>%
               filter(report_start_diff >= 0 & report_start_diff< 50000) #filter outliers

```

```{r}

tmap_mode("view")

#Load ward data
setwd("C:/Users/rchlr/Wint_inst/big_data_project/mapping/")
ward <- read_sf("Wards_from_2022.shp")

#Map 
dc_wards <- tm_shape(ward)+
  tm_polygons(col= "white", lwd= 3)+
  tm_layout(title = "Crimes Near EMS Locations", title.position = c("TOP", "center"))

  

#Violent Crime- Points

viol_sfplot<-report_data%>%
    st_as_sf(
      coords = c("LONGITUDE", "LATITUDE")
    )

viol_map <- tm_shape(viol_sfplot)+ 
  tm_dots(
    size= .005, col= "VIOLENT_CRIME", 
    pal = c("blue", "red"),
    breaks= c(0, 1, 1)
    )

#EMS- Points
ems_sfplot <- station.locations %>% 
  st_as_sf(
    coords = c("LONGITUDE", "LATITUDE")
  )

ems_map <- tm_shape(ems_sfplot)+
            tm_dots(size= .05, col = 'green')

#Combine

add_maps <-  dc_wards + viol_map + ems_map  
add_maps
```

### Mapping Methods

To prepare this EMS and Crime location map, we used the `sp` and `tmap` packages instead of `ggplot2` and `plotly`. We are most familiar with latter packages but the `sp` package included the function, `read-sf()`, that was able to use gis imaging to recognize the ward data in the `.shp`. Since the ward does not have discrete longitude and latitude data, this ability provided by the `sp` was vital. The `tmap` works best with the `sp`, so once we read in the data, it is converted into a map using the `tm_shape()` function in `tmap`. Even though we could use `ggplot()` to plot the longitude and latitude coordinates, we instead use the `st_as_sf()` to plot the EMS and VIOLENT_CRIME points. Then, we add (+) the three individual maps into one so they can overlap the points and ward boundaries.

## General Linear Model (GLM)

Another statistical model we attempt to run is the general linear model, GLM. The "VIOLENT_CRIME" is the binary variable, predicted outcome, and the "report_start_diff" is a vector of predictor variables. The "report_start_diff" is the time difference between our report and start date. We hope to see that the greater the time difference between the report and start date was, it would most likely be a nonviolent crime. Our GLM summary supports our results because it confirms violent crimes are taken more seriously and/are more urgent. The intercept is 1.629e -01 and the coefficient is -5.707e-16. This means when the time difference is at zero, the type of crime outcome would be 1.629e -01 which is closer to nonviolent (0). Then, for every hour increase, the outcome would be decreased by -5.707e-16. Therefore, this would result in an absolute nonviolent crime.

```{r}
#GLM Plot
report_data %>%
  ggplot(aes(x = report_start_diff, y = VIOLENT_CRIME)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(
    title = "Nonviolent and Violent Crime",
    subtitle =  "Difference Between Report and Start Date (hours) ",
    xlab = " Report Date - Start Date  ",
    ylab = "Violent Crime"
  )
glm_model <- glm(VIOLENT_CRIME ~ report_start_diff, data= report_data)
summary(glm_model)

```

On the other hand, our visualization does not portray such confidence. It depicts a negative exponential slope, yet the traditional S-shape curve does not form. When looking more into why our data is not performing as expected; some possibilities could be the unreliable reporting, the proportions of the nonviolent and violent crimes. Our data is majority nonviolent crime (84% vs 16%) possibly resulting in our model to over fit. Also, we must filter out negative time differences we calculated which shows evidence of inaccuracy between the recording process causing the misshape in the GLM visual. Regardless of the errors, from the measures of central tendency, it appears that violent crime is most likely to be reported faster than a nonviolent crime. Violent crime (0) has a smaller mean of 55.8 hours compared to the nonviolent (0), 77.1 hours. The median is less impacted by the outliers and supports the following trend: violent crime (0), 1.50 hours, and nonviolent (1), 5.70 hours.

#### Proportion

```{r}
print(prop.table(table(report_data$VIOLENT_CRIME)) * 100 )#Proportions of Non vs Violent Crime are not equivalent Nonviolent = 84.16% & Violent =15.84%

```

#### Central Tendency Measurements

```{r}
averages <- report_data %>%
  group_by(VIOLENT_CRIME) %>%
  summarise(mean_hours = mean(report_start_diff, na.rm = TRUE),
            median_hours = median(report_start_diff, na.rm = TRUE),
            min_hours = min(report_start_diff, na.rm = TRUE),
            max_hours = max(report_start_diff, na.rm = TRUE))
averages

```

### Classification Based Models for Predicting Crime Type

We start off by cleaning our data a little more to remove NAs to support our modeling and then split it into training and testing sets.

```{r}
library(tidyverse)
library(olsrr)
library(randomForest)
library(caret)
library(ggplot2)
library(dplyr)

set.seed(123)

# remove all of the NA data
df_crime = na.omit(report_data)

# convert our target variable into a factor
df_crime$VIOLENT_CRIME = as.factor(df_crime$VIOLENT_CRIME)

# create an hour timestamp
df_crime = df_crime %>% 
  mutate(HOUR = substr(TIME, start = 1, stop = 2))

# convert Month into a factor as well
df_crime$MONTH = as.factor(df_crime$MONTH)

# Create a vector of indices for the train-test split
train_indices <- createDataPartition(df_crime$VIOLENT_CRIME, p = 0.8, list = FALSE)

# Create the training set
train_df <- df_crime[train_indices, ]

# Create the testing set
test_df <- df_crime[-train_indices, ]
```

Next we use a logistic regression model to identify significant features to help explain crime type and to see if we can use the model to perform any predictions for crime type based on the training and testing data.

```{r}
logistic_model <- glm(VIOLENT_CRIME ~ SHIFT + HOUR + YEAR + MONTH + DOW + WARD + NEIGHBORHOOD_CLUSTER, data = train_df, family = "binomial")

# Summary of the model
summary(logistic_model)
```

We find that all of our selected features have some significant categories in them. Now let's test it.

```{r}
# create our predictions
log_predictions <- predict(logistic_model, newdata = test_df, type = "response")

# we need to convert our predictions to a binary
threshold <- 0.5
binary_pred <- factor(as.numeric(log_predictions>threshold))

# measure our accuracy
accuracy <- mean(test_df$VIOLENT_CRIME == binary_pred)

# print out the matrix
print(confusionMatrix(test_df$VIOLENT_CRIME, binary_pred))
```

While our model has a high accuracy and sensitivity, its specificity (True Negatives vs False Positives) was only 53% which underscores the importance of using more than just accuracy when judging classification models.

Moving on we will try a Random Forest model to see if we can boost our predictive capabilities with the understanding that we are moving more towards utilizing a black-box model type that reduces interpret-ability.

```{r}
rand_forest_model <- randomForest(VIOLENT_CRIME ~ SHIFT + HOUR + YEAR + MONTH + DOW + WARD, data = train_df, ntree = 100, mtry = 3)

# create our predictions
rf_predictions <- predict(rand_forest_model, newdata = test_df)

# measure our accuracy
accuracy <- mean(test_df$VIOLENT_CRIME == rf_predictions)

# print out the matrix
print(confusionMatrix(test_df$VIOLENT_CRIME, rf_predictions))

# print out our accuracy score
print(paste("Accuracy:", accuracy))
```

Our Random Forest model actually performs worse in the specificity metric than our logistic regression model despite changes to our hyper-parameters. We believe this points towards needing better variables beyond what we were able to collect and engineer.

##Discussion Violent crime had no correlation with EMS locations, contrary to what we expected. IF we were to continue this research, we would want to gain access to EMS response data as well as 911 operation calls in order to determine if there is any overlay within crime calls versus EMS calls. We would additionally build a database of cities similar to D.C. in regards to population, population density, and crime rates among other factors to deduce whether D.C. ranks higher or lower among the rates of violent and nonviolent crime. We considered creating a cross-validation of past year DC crime datasets to then predict crime years, but the cross-validation that we looked at was skewed due to 2020 and the drop in crime rates during COVID. We also looked at utilizing the 'Shifts' column that is used by MPD to split up crimes by 'day,' 'evening,' or 'midnight,' but we found two barriers to completing these. One was that the shift column only indicated reporting time, and thus the crime could have taken place during one shift but then reported during another. Another barrier was that the times of the three shifts were changed in mid-2020, meaning that we would have had to comb through all the data and change the applicable shifts. We found that it was easier as well as much more interesting to look at hours of the day instead of shift timing.

## Discussion

Violent crime has no correlation with EMS locations, contrary to our expectation. If we were to continue this research, we would want to gain access to EMS response data as well as 911 operation calls in order to determine if there is any overlay within crime calls versus EMS calls. We would additionally build a database of cities similar to D.C. in regard to population, population density, and crime rates among other factors to deduce whether D.C. ranks higher or lower among the rates of violent and nonviolent crime. We considered creating a cross-validation of past year DC crime datasets to then predict crime years, but the cross-validation that we looked at was skewed due to 2020 and the decrease in crime rates during COVID. Part of this consideration was to instead look at crime just from 2008-2019 to remove 2020 from the dataset completely, but this would limit our ability to predict crime in 2024, as there have been increasing rates of crime from 2021-2023.

Looking at National crime data, it would be interesting to look at violent and nonviolent crime to see if DC had similar rates for each compared to a national level, but national crime data had different classifications for violent and nonviolent crime. The counts for some of the crimes at the DC level, like sex abuse, are so small that it would be insignificant to look at them from such a broad scale.

We also considered utilizing the ‘Shifts’ column that is used by MPD to split up crimes by ‘day,’ ‘evening,’ or ‘midnight,’ but we found two barriers to completing these. One was that the shift column only indicated reporting time, and thus the crime could have taken place during one shift but then reported during another. Another barrier was that the times of the three shifts were changed in mid-2020, meaning that we would have had to comb through all the data and change the applicable shifts. We found that it was easier as well as much more interesting to look at hours of the day instead of shift timing.

Finally, we would have loved to look at social network analyses on perceived safety in D.C. and used that to compare to the actual number of crimes that occur in different areas of the city. This would be especially interesting with the amount of news headlines that suggest that violent crime is much more common than it may be. Or on the opposite spectrum, maybe there are fewer violent crimes that are being reported so that the actual number of violent crimes is much higher than it is perceived to be.

## Sources

Anderson, C. A. (1987). Temperature and Aggression. Journal of Personality and Social Psychology, 52 (6), 1161-1173. Colosimo, C., Yon, J. R., Ballesteros, S. R., Walsh, N., Talukder, A., Ham, P. B., Abuzeid, A. M., & Mentzer, C. J. (2021). Geospatial relationship of trauma and violent crime: An analysis of violent crime and trauma center utilization. Trauma, 23(3), 230--237. <https://doi.org/10.1177/1460408620950882> Crime Incidents in 2008-2023. (2024). $$dataset$$. <https://opendata.dc.gov/datasets/crime-incidents-in-2015/explore> Eckberg, D. (2015). Trends in conflict: Uniform crime reports, the national crime victimization surveys, and the lethality of violent crime. Homicide Studies, 19(1), 58--87. <https://doi.org/10.1177/1088767914557810> FEMS Station Locations and First Due Areas. (n.d.). $$dataset$$. <https://opendata.dc.gov/apps/fire-and-ems-station-locations/explore> Gottfredson, D. C., & Soulé, D. A. (2005). The timing of property crime, violent crime, and substance use among juveniles. Journal of Research in Crime and Delinquency, 42(1), 110--120. <https://doi.org/10.1177/0022427804266563> Hibdon, J., Telep, C. W., & Huff, J. (2021). Going beyond the blue: The utility of emergency medical services data in understanding violent crime. Criminal Justice Review, 46(2), 190--211. <https://doi.org/10.1177/0734016821999700> Irvin-Erickson, Y., & La Vigne, N. (2015). A spatio-temporal analysis of crime at washington, dc metro rail: Stations' crime-generating and crime-attracting characteristics as transportation nodes and places. Crime Science, 4(1), 14. <https://doi.org/10.1186/s40163-015-0026-5> Mazeika, D. (2023). The effect of unreported gun-related violent crime on crime hot spots. Security Journal, 36(1), 101--117. <https://doi.org/10.1057/s41284-022-00329-2> Orme-Johnson, D. W., Cavanaugh, K. L., Dillbeck, M. C., & Goodman, R. S. (2022). Field-effects of consciousness: A seventeen-year study of the effects of group practice of the transcendental meditation and tm-sidhi programs on reducing national stress in the united states. World Journal of Social Science, 9(2), 1. <https://doi.org/10.5430/wjss.v9n2p1> Ousey, G. C., Wilcox, P., & Schreck, C. J. (2015). Violent victimization, confluence of risks and the nature of criminal behavior: Testing main and interactive effects from Agnew's extension of General Strain Theory. Journal of Criminal Justice, 43(2), 164--173. <https://doi.org/10.1016/j.jcrimjus.2015.02.006>
